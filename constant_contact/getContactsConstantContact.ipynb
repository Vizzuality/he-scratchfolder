{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do list:\n",
    "- limit the getting of data using a date\n",
    "- try to get the token from the url\n",
    "- clean functions that create `gis` as this will be done only once at the begining of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeRequest(url, headers, payload):\n",
    "    \n",
    "    try:\n",
    "    ## Create empty object first\n",
    "        r_json = {}\n",
    "    \n",
    "    ## cleaner way of using requests\n",
    "        response = requests.get(url, headers=headers, data=payload)\n",
    "\n",
    "    except:\n",
    "        print(\"There was an problem in the request :(\")\n",
    "        return None\n",
    "\n",
    "    ## always nice to print the url as a sanity check\n",
    "    print(response.url)\n",
    "\n",
    "    # if succesful, populate your response json\n",
    "    if  response.status_code == 200:\n",
    "            r_json = response.json()\n",
    "    else:\n",
    "        print(f'Failed to get data {response.status_code}, {response.json()}')\n",
    "    \n",
    "    return r_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strict_reg_exp(to_search):\n",
    "    try:\n",
    "        reg_exp = f\"^{to_search}$\"\n",
    "    except:\n",
    "        print(\"There was a problem with the string.\")\n",
    "    return reg_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchContactListsID(r_json, reg_exp):\n",
    "    try:\n",
    "        l_json = r_json.get(\"lists\", [])\n",
    "        assert type(l_json) is list and len(l_json) is not 0,  \"Error with l_json\"\n",
    "        sel_contact_dict = {\n",
    "        d['name']: d.get('list_id', '')\n",
    "        for d in l_json\n",
    "        if re.search(reg_exp, d['name']) != None\n",
    "        }        \n",
    "    except:\n",
    "        print(\"There was a problem with the structure of the json\")\n",
    "    return sel_contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestURLbyListID(id_contact_list):\n",
    "    try:\n",
    "        url = f\"https://api.cc.email/v3/contacts?lists={id_contact_list}&include=street_addresses&limit=500&include_count=false\"\n",
    "    except:\n",
    "        print(\"There was a problem with the id.\")\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContactsLocation(r_json):\n",
    "    try:\n",
    "        contacts_list = []\n",
    "        l_json = r_json.get(\"contacts\", [])\n",
    "        for d in l_json:\n",
    "            street_address = d.get('street_addresses', [{}])#[0]\n",
    "            if street_address:\n",
    "                street_address = street_address[0]\n",
    "                postal_code = street_address.get(\"postal_code\", None)\n",
    "                country = street_address.get(\"country\", None)\n",
    "                if postal_code and country:\n",
    "                    contact_dict = {\n",
    "                        'contact_id': d.get('contact_id', ''), ## Need a fallback for contact_id? No, there is always a contact_id\n",
    "                        'postal_code': postal_code,\n",
    "                        'country': country\n",
    "                    }\n",
    "                    contacts_list.append(contact_dict)  \n",
    "        df = pd.DataFrame(contacts_list)\n",
    "    except:\n",
    "        print(\"There was a problem with the structure of the json\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missLocation(r_json, df):\n",
    "    try: \n",
    "        l_json = r_json.get(\"contacts\", [])\n",
    "        all_contacts_list = []\n",
    "        for d in l_json:\n",
    "            all_contacts_list.append(d.get('contact_id', ''))\n",
    "        original_set = set(all_contacts_list)\n",
    "        located_set = set(df.contact_id)\n",
    "        contact_diff = original_set.difference(located_set)\n",
    "    except:\n",
    "        print(\"There was a problem with the structure of the json\")\n",
    "    return contact_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLocationCsv(df, csvName):\n",
    "    try:\n",
    "        csv_file = f'./{csvName}.csv'\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"{csv_file} written\")\n",
    "    except:\n",
    "        print(\"The csv hasn't been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = \".env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(env_path) as f:\n",
    "    env = {}\n",
    "    for line in f:\n",
    "        env_key, _val = line.split(\"=\")\n",
    "        env_value = _val.split(\"\\n\")[0]\n",
    "        env[env_key] = env_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = env['cc_api_key']\n",
    "token = env['cc_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the token put this in the web browser: https://api.cc.email/v3/idfed?client_id={api_key}&redirect_uri=https://localhost&response_type=token&scope=contact_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"https://api.cc.email/v3/idfed?client_id={api_key}&redirect_uri=https://localhost&response_type=token&scope=contact_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then update the `.env` file. Is there a way of getting the url where this get call takes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_lists_of_interest = [\"Educator Ambassadors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_element = contact_lists_of_interest[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data from Constant Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  'Authorization': f'Bearer {token}'\n",
    "}\n",
    "payload = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.cc.email/v3/contact_lists?include_count=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_contact_lists = executeRequest(url, headers, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = {} #this dictionary should be used to log the contacts_without_location\n",
    "for list_element in contact_lists_of_interest:\n",
    "    cl_to_search = create_strict_reg_exp(list_element)\n",
    "    id_dict = searchContactListsID(r_json = r_contact_lists, reg_exp = cl_to_search)\n",
    "    url_contacts = requestURLbyListID(id_dict[list_element])\n",
    "    r_contacts = executeRequest(url_contacts, headers, payload)\n",
    "    contacts_location_df = getContactsLocation(r_contacts)\n",
    "    contacts_without_location = missLocation(r_contacts,contacts_location_df) #this should be written in some kind of log\n",
    "    writeLocationCsv(contacts_location_df, list_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_to_search = create_strict_reg_exp(list_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_without_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once the csv is ready it can be published in arcgis online via the arcgis api\n",
    "Here there can be different cases:\n",
    "- publish a new service, if the list is a new one\n",
    "- fully overwrite a service\n",
    "- append data to a service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from copy import deepcopy\n",
    "from arcgis.geocoding import geocode\n",
    "from arcgis import geometry\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation on setting the content_status [here](https://developers.arcgis.com/python/api-reference/arcgis.gis.toc.html#arcgis.gis.Item.content_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publishCSVasFS(csvName, sharing = \"everyone\", aol_folder_name = \"constant_contact\", aol_username = env['aol_username'], aol_password = env['aol_key']):\n",
    "    try:\n",
    "        gis = GIS(\"https://eowilson.maps.arcgis.com\", aol_username, aol_password)\n",
    "        if gis.content.is_service_name_available(csvName, \"featureService\"):\n",
    "            print(f\"Service name {csvName} is available\")\n",
    "            csv_file = f'./{csvName}.csv'\n",
    "            csv_item = gis.content.add({}, csv_file)\n",
    "            csv_lyr = csv_item.publish(None,  { 'CountryCode' : 'country',\n",
    "                                            'Postal' : 'postal_code'} )\n",
    "            #check how many entries has the service, compared to the number of entries in the csv, return entries that have been removed\n",
    "            flayer_collection = FeatureLayerCollection.fromitem(csv_lyr)\n",
    "            searched_flayer = flayer_collection.layers[0] \n",
    "            nber_features = searched_flayer.query(return_count_only=True)\n",
    "            print(f\"The service {csvName} has been published. The service has {nber_features} entries\")\n",
    "            print(f\"Moving service {csvName} to {aol_folder_name} in ArcGIS Online...\")\n",
    "            csv_item.move(aol_folder_name)\n",
    "            csv_lyr.move(aol_folder_name)\n",
    "            print(f\"Service {csvName} has been moved to {aol_folder_name} in ArcGIS Online\")\n",
    "            #sharing\n",
    "            if sharing == \"everyone\":\n",
    "                csv_lyr.share(everyone=True, org=False, groups=None, allow_members_to_edit=False)\n",
    "            sharing_prop = csv_lyr.shared_with\n",
    "            if sharing_prop['everyone']==True:\n",
    "                print(f\"shared with everyone\")\n",
    "            else:\n",
    "                print(f\"not public layer, for this layer to be used it has to be public or the urls have to be whitelisted\")            \n",
    "            #not allowing deleting\n",
    "            csv_lyr.protect()\n",
    "            try:\n",
    "                csv_lyr.delete()\n",
    "                print(\"The service has not been published.\")\n",
    "            except:\n",
    "                print(\"The detele protection is activated.\")\n",
    "            #mark deprecated\n",
    "            # it is possible to check the status with csv_item.content_status\n",
    "            return csv_lyr.id\n",
    "        else:\n",
    "            print(\"The service name is not available, try overwritting, appending the data or a different service name\")\n",
    "        \n",
    "    except:\n",
    "        print(\"The csv hasn't been published\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishCSVasFS(csvName = testing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findItemGetID(csvName, aol_username = env['aol_username'], aol_password = env['aol_key']):\n",
    "    try:\n",
    "        gis = GIS(\"https://eowilson.maps.arcgis.com\", aol_username, aol_password)\n",
    "        searched_item = gis.content.search(csvName, item_type = \"Feature Layer\")\n",
    "        if len(searched_item) == 1:\n",
    "            i = searched_item[0]\n",
    "            reg_exp = create_strict_reg_exp(csvName)\n",
    "            if re.search(reg_exp, i.title)!= None:    \n",
    "                return i.id\n",
    "            else:\n",
    "                print(f\"The service {csvName} does not exist with that exact name. \")\n",
    "        else:\n",
    "            print(f\"The csvName provided returns {len(searched_item)} results.\")\n",
    "    except:\n",
    "        print(\"There was a problem finding the item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overwrite follow [this notebook from ESRI](https://developers.arcgis.com/python/sample-notebooks/overwriting-feature-layers/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwriteFSwithCSV(csvName, item_id, aol_username = env['aol_username'], aol_password = env['aol_key']):\n",
    "    try:\n",
    "        gis = GIS(\"https://eowilson.maps.arcgis.com\", aol_username, aol_password)\n",
    "        searched_item = gis.content.get(item_id)             \n",
    "        csv_file = f'./{csvName}.csv'\n",
    "        try:\n",
    "            flayer_collection = FeatureLayerCollection.fromitem(searched_item)\n",
    "            overwrite_message = flayer_collection.manager.overwrite(csv_file)\n",
    "            if overwrite_message['success'] == True:\n",
    "                searched_flayer = flayer_collection.layers[0] \n",
    "                nber_features = searched_flayer.query(return_count_only=True)\n",
    "                print(f\"The service {csvName} has been overwritten. The service has {nber_features} entries\")\n",
    "        except:\n",
    "                print(\"There was a problem overwriting the service\")                \n",
    "    except:\n",
    "        print(\"The service hasn't been overwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_id = findItemGetID(csvName = testing_val)\n",
    "overwriteFSwithCSV(csvName = testing_val, item_id = testing_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To append follow [this notebook from ESRI](https://developers.arcgis.com/python/sample-notebooks/updating-features-in-a-feature-layer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendCSVtoFS(csvName, item_id, aol_username = env['aol_username'], aol_password = env['aol_key']): \n",
    "    csv_file = f'./{csvName}.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    item = gis.content.get(item_id)\n",
    "    flayer = item.layers[0]\n",
    "    fset = flayer.query()\n",
    "    overlap_rows = pd.merge(left = fset.sdf, right = df, how='inner', on = 'contact_id')\n",
    "    #get number of overlap rows\n",
    "    features_for_update = [] #list containing corrected features\n",
    "    all_features = fset.features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureSet(item_id):\n",
    "    item = gis.content.get(item_id)\n",
    "    flayer = item.layers[0]\n",
    "    fset = flayer.query()\n",
    "    return fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkOverlap(csvName, fset):\n",
    "    try:\n",
    "        csv_file = f'./{csvName}.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "        overlap_rows = pd.merge(left = fset.sdf, right = df, how='inner', on = 'contact_id')\n",
    "        if overlap_rows:\n",
    "            return overlap_rows\n",
    "        else:\n",
    "            return False \n",
    "    except:\n",
    "        print(\"There has been a problem checking row overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeaturesInService(overlap_rows, fset):\n",
    "    try:\n",
    "        all_features = fset.features\n",
    "        features_for_update = [] #list containing corrected features\n",
    "        for contact_id in overlap_rows['contact_id']:\n",
    "            # get the feature to be updated\n",
    "            original_feature = [f for f in all_features if f.attributes['contact_id'] == contact_id][0]\n",
    "            feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "            print(str(original_feature))\n",
    "\n",
    "            # get the matching row from csv\n",
    "            matching_row = df.where(df.contact_id == contact_id).dropna()\n",
    "\n",
    "            # from the csv geocode the country and postcode\n",
    "            address = {\"CountryCode\": matching_row['country'][0], \"Postal\": int(matching_row['postal_code'][0])}\n",
    "            add_loc = geocode(address)\n",
    "            #get geometries in the destination coordinate system\n",
    "            input_geometry = add_loc[0]['location']\n",
    "            #print(input_geometry)\n",
    "            output_geometry = geometry.project(geometries = [input_geometry],\n",
    "                                               in_sr = 4326, \n",
    "                                               out_sr = fset.spatial_reference['latestWkid'],\n",
    "                                              gis = gis)\n",
    "            #print(output_geometry)\n",
    "            # assign the updated values\n",
    "            feature_to_be_updated.geometry = output_geometry[0]    \n",
    "            feature_to_be_updated.attributes['contact_id'] = matching_row['contact_id'].values[0]\n",
    "            feature_to_be_updated.attributes['postal_code'] = matching_row['postal_code'].values[0]\n",
    "            feature_to_be_updated.attributes['country'] = matching_row['country'].values[0]\n",
    "\n",
    "\n",
    "            #add this to the list of features to be updated\n",
    "            features_for_update.append(feature_to_be_updated)\n",
    "\n",
    "            #print(str(feature_to_be_updated))\n",
    "            #print(\"========================================================================\")\n",
    "            #break\n",
    "        if features_for_update:\n",
    "            message = flayer.edit_features(updates= features_for_update)\n",
    "            print(message)\n",
    "        else:\n",
    "            print(\"no features were updated\")\n",
    "    except:\n",
    "        print(\"There was a problem updating the features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNewRows(csvName, fset, overlap_rows):\n",
    "    try:\n",
    "        csv_file = f'./{csvName}.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "        new_rows = df[~df['contact_id'].isin(overlap_rows['contact_id'])]\n",
    "    if new_rows:\n",
    "            return new_rows\n",
    "        else:\n",
    "            return False \n",
    "    except:\n",
    "        print(\"There has been a problem checking for new rows\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNewFeatures(new_rows, fset):\n",
    "    try:\n",
    "        features_to_be_added = []\n",
    "        template_feature = deepcopy(fset[0])\n",
    "        for row in new_rows.iterrows():\n",
    "            #print(row['postal_code'], row['country'])   \n",
    "            address = {\"CountryCode\": row['country'], \"Postal\": row['postal_code']}\n",
    "            add_loc = geocode(address, out_fields=\"City,Country\")\n",
    "            #print(add_loc)\n",
    "            if add_loc:\n",
    "                new_feature = deepcopy(template_feature)\n",
    "                #get geometries in the destination coordinate system\n",
    "                input_geometry = add_loc[0]['location']\n",
    "                output_geometry = geometry.project(geometries = [input_geometry],\n",
    "                                               in_sr = 4326, \n",
    "                                               out_sr = fset.spatial_reference['latestWkid'],\n",
    "                                              gis = gis)\n",
    "                 # assign the updated values\n",
    "                new_feature.geometry = output_geometry[0]\n",
    "                new_feature.attributes['contact_id'] = int(row[1]['contact_id'])\n",
    "                new_feature.attributes['state'] = row[1]['state']\n",
    "                new_feature.attributes['capital'] = row[1]['capital']\n",
    "\n",
    "\n",
    "                #add this to the list of features to be updated\n",
    "                features_to_be_added.append(new_feature)\n",
    "\n",
    "            #break\n",
    "        if features_to_be_added:\n",
    "            flayer.edit_features(adds = features_to_be_added)\n",
    "        else:\n",
    "            print(\"no features were added\")\n",
    "    except:\n",
    "        print(\"There has been a problem adding new features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locationNotMapped(csvName, item_id):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvToArcgis(csvName, action, gis, aol_folder_name = \"constant_contact\", aol_username = env['aol_username'], aol_password = env['aol_key']):\n",
    "    if action == \"publish\":\n",
    "        published_id = publishCSVasFS(csvName)\n",
    "        locationNotMapped(csvName, published_id)\n",
    "    if action == \"overwrite\":\n",
    "        item_id = findItemGetID(csvName)\n",
    "        overwriteFSwithCSV(csvName, item_id)\n",
    "        locationNotMapped(csvName, item_id)\n",
    "    if action == \"append\":\n",
    "        item_id = findItemGetID(csvName)\n",
    "        fset = getFeatureSet(item_id)\n",
    "        overlapRows = checkOverlap(csvName, fset)\n",
    "        if overlapRows:\n",
    "            updateFeaturesInService(csvName, fset)\n",
    "            newRows = checkNewRows(csvName, fset, overlap_rows)\n",
    "            if newRows:\n",
    "                addNewFeatures(newRows, fset) \n",
    "        locationNotMapped(csvName, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aol_password = env['aol_key']\n",
    "aol_username = env['aol_username']\n",
    "gis = GIS(\"https://eowilson.maps.arcgis.com\", aol_username, aol_password)\n",
    "csvToArcgis(csvName, action, gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
