{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National Report Cards: species pictures\n",
    "\n",
    "### 1. Add 2 new columns to vertebrate table:\n",
    "1. the species url if it has a picture\n",
    "2. the highlight order for the species. The cirteria for species selection is: \n",
    "    1. less stewardship \n",
    "    2. smaller range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Run this just once\n",
    "# env_path = \"/Users/tamarahuete/opt/anaconda3/envs/arcgis/.env\"\n",
    "# env_path\n",
    "# with open(env_path) as f:\n",
    "#     env = {}\n",
    "#     for line in f:\n",
    "#         env_key, _val = line.split(\"=\")\n",
    "#         env_value = _val.split(\"\\n\")[0]\n",
    "#         env[env_key] = env_value\n",
    "# aol_password = env['aol_key']\n",
    "# aol_username = env['aol_username']\n",
    "\n",
    "\n",
    "# # here we are using the eowilson arcgis online, change to the appropriate gis online organisation account.\n",
    "# gis = GIS(\"https://eowilson.maps.arcgis.com\", aol_username, aol_password, profile = \"half_earth_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(profile = \"half_earth_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def create_strict_reg_exp(to_search):\n",
    "    try:\n",
    "        reg_exp = f\"^{to_search}$\"\n",
    "        #logging.info(f\"regular expression is: {reg_exp}\")\n",
    "    except:\n",
    "        print(\"There was a problem with the string.\")\n",
    "    return reg_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findItemGetID(csvName, gis):\n",
    "    try:\n",
    "        searched_item = gis.content.search(csvName, item_type = \"Feature Layer\")\n",
    "        for i in searched_item:\n",
    "            reg_exp = create_strict_reg_exp(csvName)\n",
    "            if re.search(reg_exp, i.title)!= None:    \n",
    "                #logging.info(f\"{csvName} has the id: {i.id}\")\n",
    "                return i.id\n",
    "    except:\n",
    "        print(\"There was a problem finding the item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFlayerFromID(item_id):\n",
    "    item = gis.content.get(item_id)\n",
    "    flayer = item.layers[0]\n",
    "    return flayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSDFfromFlayer(flayer):\n",
    "    sdf = pd.DataFrame.spatial.from_layer(flayer)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get the ID of the table. No extension needed. Not working for some reason\n",
    "sp_country_id  = findItemGetID('Terrestrial_vertebrates_by_country_20200617_stewardship',gis)\n",
    "#sp_country_id ='159c6daf94f0498883186d052f033759'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_flayer =getFlayerFromID(sp_country_id)\n",
    "spc_flayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp_widget_id  = '4688587cf07748b2964e9618b31b66e5'\n",
    "spw_flayer =getFlayerFromID(sp_widget_id)\n",
    "spw_flayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_country = pd.DataFrame.spatial.from_layer(spc_flayer)\n",
    "#sdf_widget=pd.DataFrame.spatial.from_layer(spw_flayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### returns a sdf from the query\n",
    "#### For SQL queries very important. Outer \"\", inner ''\n",
    "df = spw_flayer.query(where=\"url_sp like 'https%'\").sdf\n",
    "#takes 20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# len(df)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### keep a subset of the table with just necessary columns\n",
    "df_simple = df[['species_name','url_sp']]\n",
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eliminate duplicated fields\n",
    "df_unique = df_simple.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #(1044875, 13)\n",
    "df_unique.shape #(11425, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_with_urls =pd.merge(left=sdf_country, right = df_unique, left_on='species',right_on = 'species_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp_with_urls) ### 75449 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_with_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted= sp_with_urls.sort_values(by = ['countryname','speciesgroup','stewardship','AREA_KM2'])\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### addd new column with ranking\n",
    "df_sorted['highlight'] = df_sorted.groupby(['countryname','speciesgroup']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('species_table_highlights_for_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### upload table back from csv\n",
    "df_sorted = pd.read_csv('species_table_highlights_for_url.csv')\n",
    "df_sorted = df_sorted.drop(columns=['Unnamed: 0'])\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### merge with the original table on arcGIS based on the Object ID. Left merge\n",
    "df_sorted.sort_values(by = ['ObjectId']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_reduced = df_sorted[['ObjectId','url_sp','highlight']]\n",
    "updated =sdf_country.merge(df_sorted_reduced,on='ObjectId',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(updated)==len(sdf_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### keep a local copy\n",
    "updated.to_csv('species_table_highlights_for_url_all_ObjectId.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add new columns to vertebrate table in ArcGIS\n",
    "We have a table with the species highlight ranking and urls for pictures. \n",
    "Only missing attaching these fields to the original table in ArcGIS\n",
    "Follow steps in [this notebook](https://github.com/Vizzuality/he-scratchfolder/blob/master/addFieldsToFeatureService.ipynb) and instructions on [this wiki](https://github.com/Vizzuality/sci-team-wiki/wiki/ESRI#adding-new-fields-to-the-service-notebook-with-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS, GroupManager\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureLayer\n",
    "from copy import deepcopy\n",
    "from arcgis import geometry\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(profile = \"half_earth_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFieldsToBeAdded(flayer, csv_table):\n",
    "    flayer_fields = flayer.manager.properties.fields\n",
    "    template_field = dict(deepcopy(flayer_fields[0]))\n",
    "    sdf = getSDFfromFlayer(flayer)\n",
    "    new_field_names = list(csv_table.columns.difference(sdf.columns))\n",
    "    \n",
    "    fields_to_be_added = []\n",
    "    for new_field_name in new_field_names:\n",
    "        current_field = deepcopy(template_field)\n",
    "        dt = csv_table[new_field_name].dtypes\n",
    "        \n",
    "        if dt == 'O':\n",
    "            #put the type to character\n",
    "            current_field['sqlType'] = 'sqlTypeOther'\n",
    "            current_field['type'] = 'esriFieldTypeString'\n",
    "            #current_field['length'] = 8000\n",
    "        if dt == 'float64':\n",
    "            #put the type to double\n",
    "            current_field['sqlType'] = 'sqlTypeOther'\n",
    "            current_field['type'] = 'esriFieldTypeDouble'\n",
    "            #current_field['length'] = 8000      \n",
    "\n",
    "        current_field['name'] = new_field_name.lower()\n",
    "        current_field['alias'] = new_field_name\n",
    "        current_field['nullable'] = True\n",
    "        current_field['editable'] = True\n",
    "        fields_to_be_added.append(current_field)\n",
    "    return fields_to_be_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeaturesForUpdate(flayer, csv_table, fields_to_be_added, id_field_in_csv, id_field_in_service):\n",
    "    fset2 = flayer.query()\n",
    "    features2 = fset2.features\n",
    "    features_for_update = []\n",
    "    for country_id in csv_table[id_field_in_csv]:\n",
    "        try:\n",
    "            # get the matching row from csv\n",
    "            matching_row = csv_table.where(csv_table[id_field_in_csv] == country_id).dropna()\n",
    "\n",
    "            #print(str(country_id) + \" Adding additional attributes for: \" + matching_row['iso3'].values[0])\n",
    "\n",
    "            # get the feature to be updated\n",
    "            assert  len([f for f in features2 if f.attributes[id_field_in_service] == country_id]),  \"id not matched\"\n",
    "            original_feature = [f for f in features2 if f.attributes[id_field_in_service] == country_id][0]\n",
    "            feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "            # assign the updated values\n",
    "            for field in fields_to_be_added:\n",
    "                feature_to_be_updated.attributes[field['name']] = matching_row[field['name']].values[0]\n",
    "                #add this to the list of features to be updated\n",
    "                features_for_update.append(feature_to_be_updated)\n",
    "            #print(str(country_id) + \" Done additional attributes for: \" + matching_row['countryname'].values[0])\n",
    "    \n",
    "        except:\n",
    "            print(f\"{country_id} not available in service\")\n",
    "    return features_for_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id  = findItemGetID('Terrestrial_vertebrates_by_country_20200617_stewardship',gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flayer = getFlayerFromID(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_table = df_sorted[['ObjectId', 'url_sp','highlight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_be_added = createFieldsToBeAdded(flayer, csv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_be_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flayer.manager.add_to_definition({'fields':fields_to_be_added})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### started at 12:30, updating 162710 features, ended 16:00!!! (and failed: Parameters not valid for edit_features, because fields to be added were empty [])\n",
    "### start at 16:10 - 20:00 \n",
    "### 8:20 - 11:30\n",
    "features_for_update = createFeaturesForUpdate(flayer, csv_table, fields_to_be_added, id_field_in_csv = \"ObjectId\", id_field_in_service = \"ObjectId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_for_update) #150898?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150898 / 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_for_update[0:200])\n",
    "#0:1000\n",
    "#1001-3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_table.loc[15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148711+150898\n",
      "2187\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i =68\n",
    "start =int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i],0))\n",
    "end=int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i+1],0))\n",
    "print(f'{start}+{end}')\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 48 last feature = 107159\n",
      "finished 49 last feature = 109346\n",
      "finished 50 last feature = 111533\n",
      "finished 51 last feature = 113720\n",
      "finished 52 last feature = 115907\n",
      "finished 53 last feature = 118094\n",
      "finished 54 last feature = 120281\n",
      "finished 55 last feature = 122468\n",
      "finished 56 last feature = 124655\n",
      "finished 57 last feature = 126842\n",
      "finished 58 last feature = 129029\n",
      "finished 59 last feature = 131216\n",
      "finished 60 last feature = 133403\n",
      "finished 61 last feature = 135590\n",
      "finished 62 last feature = 137776\n",
      "finished 63 last feature = 139963\n",
      "finished 64 last feature = 142150\n",
      "finished 65 last feature = 144337\n",
      "finished 66 last feature = 146524\n",
      "finished 67 last feature = 148711\n"
     ]
    }
   ],
   "source": [
    "for i in range(48,68):\n",
    "    start =int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i],0))\n",
    "    end=int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i+1],0))\n",
    "    flayer.edit_features(updates= features_for_update[start:end])\n",
    "    print(f'finished {i} last feature = {end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flayer.edit_features(updates= features_for_update) ### API cannot handle 160k requests. I need to slip them up in blocks of 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 68 last feature = 150898\n"
     ]
    }
   ],
   "source": [
    "for i in range(68,69):\n",
    "    start =int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i],0))\n",
    "    end=int(round(np.linspace(start=0, stop=len(features_for_update), num=70)[i+1],0))\n",
    "    flayer.edit_features(updates= features_for_update[start:end])\n",
    "    print(f'finished {i} last feature = {end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test fields to be deleted from API (I have not tested it)\n",
    "json = {\n",
    "    \"fields\" : [\n",
    "    {\n",
    "      \"name\" : \"POP90_SQMI\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "result = fl.manager.delete_from_definition(json)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgis",
   "language": "python",
   "name": "arcgis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
